name: Notebook QA

on:
  workflow_call:
    inputs:
      notebooks:
        description: 'Space-separated list of notebook paths to check (default: all *.ipynb)'
        required: false
        type: string
        default: ''
      execution_runner:
        description: 'Runner for notebook execution (supports self-hosted)'
        required: false
        type: string
        default: 'ubuntu-latest'

env:
  QA_OUTPUT_DIR: qa_outputs${{ github.run_id }}

jobs:
  # Job 0: Collect notebooks to check (shared by all jobs)
  collect:
    runs-on: ubuntu-latest
    outputs:
      notebooks: ${{ steps.notebooks.outputs.files }}
    steps:
      - uses: actions/checkout@v4

      - name: Get notebooks
        id: notebooks
        run: |
          if [ -n "${{ inputs.notebooks }}" ]; then
            echo "files=${{ inputs.notebooks }}" >> $GITHUB_OUTPUT
            echo "Using specified notebooks: ${{ inputs.notebooks }}"
          else
            NOTEBOOKS=$(find . -name '*.ipynb' -not -path '*/.ipynb_checkpoints/*' | tr '\n' ' ')
            echo "files=$NOTEBOOKS" >> $GITHUB_OUTPUT
            echo "Found notebooks: $NOTEBOOKS"
          fi

  # Job 1: Static checks (fast, run on default runner)
  lint:
    needs: collect
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -el {0}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-version: latest
          activate-environment: notebook-qa
          environment-file: environment.yml
          use-mamba: true

      - name: Install QA tools
        run: |
          pip install nbqa ruff pynblint 'click<8.3' pytest-cov beautifulsoup4 lxml

      # Linting checks
      - name: (2.2.3) Run linter
        id: linter
        if: success() || failure()
        run: nbqa "ruff check" ${{ needs.collect.outputs.notebooks }}

      - name: (2.2.3) Run formatter
        id: formatter
        if: success() || failure()
        run: nbqa "ruff format --check --diff" ${{ needs.collect.outputs.notebooks }}

      - name: (2.2.3) Run pynblint
        id: pynblint
        if: success() || failure()
        run: echo ${{ needs.collect.outputs.notebooks }} | xargs -n 1 pynblint

      # Link checking with lychee (fast, Rust-based)
      - name: (1.2.3) Check links
        id: link_checker
        if: success() || failure()
        uses: lycheeverse/lychee-action@v2
        with:
          args: --verbose --no-progress ${{ needs.collect.outputs.notebooks }}
          fail: true

      # Test coverage (direct pytest-cov)
      - name: (2.3.1, 2.3.2) Check tests and coverage
        id: test_checker
        if: success() || failure()
        run: |
          if ls test_*.py *_test.py tests/*.py 2>/dev/null; then
            pytest --cov=. --cov-report=term --cov-fail-under=80
          else
            echo "No test files found, skipping coverage check"
          fi

      # Custom checks
      - name: (1.2.5) Check for DOI references
        id: doi_checker
        if: success() || failure()
        run: |
          python ${{ github.workspace }}/gha-ci-notebook-checks/process-notebooks/checkers/doi_checker.py \
            ${{ needs.collect.outputs.notebooks }}

      - name: (3.3.2) Check figure labels and sources
        id: figure_checker
        if: success() || failure()
        run: |
          python ${{ github.workspace }}/gha-ci-notebook-checks/process-notebooks/checkers/figure_checker.py \
            ${{ needs.collect.outputs.notebooks }}

      # Metadata check (inline)
      - name: (1.2.6) Check version metadata
        id: metadata_checker
        if: success() || failure()
        run: |
          found=false
          for nb in ${{ needs.collect.outputs.notebooks }}; do
            if grep -qiE "(last.?updated|version|modified|date).*[0-9]{4}" "$nb" 2>/dev/null; then
              echo "✅ Found version date in $nb"
              found=true
            elif [ -f "$(dirname "$nb")/README.md" ]; then
              if grep -qiE "(last.?updated|version|modified|date).*[0-9]{4}" "$(dirname "$nb")/README.md" 2>/dev/null; then
                echo "✅ Found version date in README.md for $nb"
                found=true
              fi
            fi
          done
          if [ "$found" = false ]; then
            echo "⚠️ No version date found in notebooks or README"
          fi

      # Accessibility check (inline)
      - name: (3.1.3) Check accessibility - alt text
        id: accessibility_checker
        if: success() || failure()
        run: |
          python << 'EOF'
          import json
          import sys
          import re

          notebooks = "${{ needs.collect.outputs.notebooks }}".split()
          issues = []

          for nb_path in notebooks:
              if not nb_path.strip():
                  continue
              try:
                  with open(nb_path) as f:
                      nb = json.load(f)
                  for i, cell in enumerate(nb.get('cells', [])):
                      if cell.get('cell_type') == 'markdown':
                          src = ''.join(cell.get('source', []))
                          # Check for images without alt text: ![]( pattern
                          if re.search(r'!\[\]\(', src):
                              issues.append(f"{nb_path}: cell {i} has image without alt text")
                          # Check HTML img tags without alt
                          if re.search(r'<img[^>]*(?<!alt=")[^>]*>', src, re.IGNORECASE):
                              if not re.search(r'<img[^>]*alt\s*=', src, re.IGNORECASE):
                                  issues.append(f"{nb_path}: cell {i} has HTML img without alt attribute")
              except Exception as e:
                  print(f"Warning: Could not check {nb_path}: {e}")

          if issues:
              print("❌ Accessibility issues found:")
              for issue in issues:
                  print(f"  - {issue}")
              sys.exit(1)
          else:
              print("✅ All images have alt text")
          EOF

      # File existence checks
      - name: (1.2.4) Check LICENSE
        id: license
        if: success() || failure()
        run: |
          if [ -s LICENSE ]; then
            echo "✅ LICENSE file is present and non-empty"
          else
            echo "❌ LICENSE file is missing or empty"
            exit 1
          fi

      - name: (4.2.3) Check CHANGELOG
        id: changelog
        if: success() || failure()
        run: |
          if [ -s CHANGELOG.md ]; then
            echo "✅ CHANGELOG.md file is present and non-empty"
          else
            echo "❌ CHANGELOG.md file is missing or empty"
            exit 1
          fi

  # Job 2: Notebook execution (resource-intensive, configurable runner)
  execute:
    needs: collect
    runs-on: ${{ inputs.execution_runner }}
    defaults:
      run:
        shell: bash -el {0}
    env:
      CDSAPI_KEY: ${{ secrets.CDSAPI_KEY }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-version: latest
          activate-environment: notebook-qa
          environment-file: environment.yml
          use-mamba: true

      - name: Install execution tools
        run: pip install ploomber-engine psutil matplotlib

      - name: Configure CDS API
        if: env.CDSAPI_KEY != ''
        run: |
          echo "url: https://cds.climate.copernicus.eu/api" > ~/.cdsapirc
          echo "key: $CDSAPI_KEY" >> ~/.cdsapirc

      - name: (2.2.1, 2.2.4, 2.2.6) Execute notebooks with memory profiling
        id: execute_notebooks
        run: |
          python << 'EOF'
          import os
          import csv
          from pathlib import Path
          from ploomber_engine import execute_notebook

          notebooks = "${{ needs.collect.outputs.notebooks }}".split()
          output_dir = os.environ.get('QA_OUTPUT_DIR', 'qa_outputs')
          Path(output_dir).mkdir(parents=True, exist_ok=True)

          failed = []
          for nb in notebooks:
              if not nb.strip():
                  continue
              print(f"\n{'='*60}")
              print(f"Executing: {nb}")
              print('='*60)
              try:
                  result = execute_notebook(
                      nb,
                      output_path=nb,
                      profile_memory=True,
                      progress_bar=False
                  )
                  # Save profiling data
                  if hasattr(result, 'profile') and result.profile:
                      csv_path = Path(output_dir) / f"{Path(nb).stem}-profiling-data.csv"
                      with open(csv_path, 'w', newline='') as f:
                          writer = csv.DictWriter(f, fieldnames=['cell', 'memory', 'runtime'])
                          writer.writeheader()
                          for i, (mem, time) in enumerate(zip(
                              result.profile.get('memory', []),
                              result.profile.get('runtime', [])
                          )):
                              writer.writerow({'cell': i, 'memory': mem, 'runtime': time})
                  print(f"✅ {nb} executed successfully")
              except Exception as e:
                  print(f"❌ {nb} failed: {e}")
                  failed.append(nb)

          if failed:
              print(f"\n❌ {len(failed)} notebook(s) failed to execute:")
              for nb in failed:
                  print(f"  - {nb}")
              exit(1)
          EOF

      - name: Upload profiling artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: notebook-profiling-${{ github.run_id }}
          path: ${{ env.QA_OUTPUT_DIR }}
          if-no-files-found: ignore
